{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "import time\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_configs(conf_dir = 'configs/lag_configs/'):\n",
    "        \n",
    "    configurations = {}\n",
    "\n",
    "    for conf in os.listdir(conf_dir):\n",
    "\n",
    "        if 'configurations' in conf:\n",
    "            configurations.update(joblib.load(conf_dir + conf))\n",
    "\n",
    "    #print('config keys:', list(configurations.keys()))\n",
    "    \n",
    "    return configurations\n",
    "\n",
    "def fill_na_configs(configs, na_val = 60*24):\n",
    "    \n",
    "    for locations in list(configs.keys()):\n",
    "        \n",
    "        for key, val in zip(configs['{}'.format(locations)].keys(), configs['{}'.format(locations)].values()):\n",
    "            \n",
    "            if pd.isna(val[0]):\n",
    "                #print(locations, key, val)\n",
    "                configs['{}'.format(locations)][key] = (configs['{}'.format(locations)][key][0], configs['{}'.format(locations)][key][1], (na_val))\n",
    "    \n",
    "    return configs\n",
    "\n",
    "\n",
    "def get_lead_ts(log):\n",
    "    \n",
    "    temp_log = log.copy()\n",
    "    temp_log = temp_log.sort_values(['case_id', 'event_id'])\n",
    "    temp_log['ts_next'] = temp_log.ts.shift(-1)\n",
    "    temp_log.loc[temp_log['activity'] == '<EOS>', 'ts_next'] = np.nan\n",
    "    \n",
    "    return log.merge(temp_log[['event_id', 'ts_next']], left_on='event_id', right_on='event_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_load_optdur(x, previous, location, config):\n",
    "    \n",
    "    target_activity = x['activity']\n",
    "    \n",
    "    offset = pd.DateOffset(minutes=0)\n",
    "    diff = pd.DateOffset(minutes=config[target_activity][location][2])\n",
    "    \n",
    "    return pd.Series([x.event_id, previous.loc[(previous.index >= x['ts']-diff-offset) & (previous.index < x['ts']-offset)].ts.count()])\n",
    "    \n",
    "\n",
    "def calc_load_activecase(x, previous):\n",
    "    \n",
    "    return pd.Series([x.event_id, previous.loc[(previous.ts <= x.ts) & (previous.ts_next >= x.ts)].ts.count()])\n",
    "\n",
    "    \n",
    "def calc_load_bos(x, previous, bosdur):\n",
    "    \"\"\"No provious event for bos, compute load at <bos> past bosdur hours\"\"\"\n",
    "    \n",
    "    if bosdur != None:\n",
    "        offset = pd.DateOffset(minutes=0)\n",
    "        diff = pd.DateOffset(hours=bosdur) #used 24 here\n",
    "\n",
    "        return pd.Series([x.event_id, previous.loc[(previous.index >= x['ts']-diff-offset) & (previous.index < x['ts']-offset)].ts.count()])\n",
    "    \n",
    "    else:\n",
    "        return pd.Series([x.event_id, 0])\n",
    "    \n",
    "\n",
    "def compute_load_bos(log, load_df, bosdur):\n",
    "    \n",
    "    previous = log_csv.loc[log_csv.activity.str.startswith('<BOS>')]\n",
    "    load_comp = log[~log.event_id.isin(np.array(load_df.event_id))].apply(lambda x: calc_load_bos(x, previous, bosdur), axis=1)\n",
    "    load_comp.columns = ['event_id', 'load']\n",
    "    \n",
    "    return load_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_load(log, location, load_state):\n",
    "    \n",
    "    load_comp = None\n",
    "    \n",
    "    previous = log.loc[log.activity == location]\n",
    "    target_log = log.loc[log.event_id.isin(np.array(previous.event_id+1))]\n",
    "    \n",
    "    if len(target_log) == 0:\n",
    "        return print('target log empty')\n",
    "    \n",
    "    if load_state == 'actcase':\n",
    "        load_comp = target_log.apply(lambda x: calc_load_activecase(x,previous), axis=1)\n",
    "    \n",
    "    elif load_state == 'optdur':\n",
    "        config = get_all_configs()\n",
    "        config = fill_na_configs(config)\n",
    "        load_comp = target_log.apply(lambda x: calc_load_optdur(x, previous, location, config), axis=1)\n",
    "        \n",
    "    load_comp.columns = ['event_id', 'load']\n",
    "    \n",
    "    return load_comp\n",
    "\n",
    "\n",
    "def compute_lag_load(log, load_state='optdur', bosdur=None):\n",
    "    \"\"\"takes as input an event log and a specification of load state, i.e. optdur/actcase.\"\"\"\n",
    "    \n",
    "    load_df = pd.DataFrame(columns=['event_id','load'])\n",
    "    \n",
    "    if load_state == 'actcase':\n",
    "        log = get_lead_ts(log)\n",
    "    \n",
    "    \n",
    "    locations = [col for col in list(set(log_csv.activity)) if ('EOS' not in col)]\n",
    "\n",
    "    for location in tqdm(locations):\n",
    "\n",
    "        load_loc = compute_load(log, location, load_state=load_state)\n",
    "        load_df = load_df.append(load_loc)\n",
    "\n",
    "    load_bos = compute_load_bos(log, load_df, bosdur)\n",
    "    load_df = load_df.append(load_bos)\n",
    "\n",
    "    return log_csv.merge(load_df, left_on='event_id', right_on='event_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv = pd.read_csv('evlog.csv', sep=',')\n",
    "log_csv.ts = log_csv.ts.apply(lambda x: x[:-4])\n",
    "log_csv.drop(log_csv.columns[0], axis=1, inplace=True)\n",
    "log_csv = dataframe_utils.convert_timestamp_columns_in_df(log_csv)\n",
    "log_csv = log_csv.sort_values('ts')\n",
    "log_csv.set_index(log_csv.ts, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_log = compute_lag_load(log_csv, load_state='actcase')\n",
    "load_log = load_log.rename(columns = {'load':'lag_load'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
